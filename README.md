# ðŸš€ Automated Daily Tech Archive

![Status](https://img.shields.io/badge/Hosted_on-UGreen_DXP4800_Plus-Portainer-blue?style=for-the-badge&logo=docker)
![Python](https://img.shields.io/badge/Python-3.9+-yellow?style=for-the-badge&logo=python)
![Automation](https://img.shields.io/badge/Automation-Cron_Job-green?style=for-the-badge&logo=linux)

This repository serves as a **fully automated data archival system**. Every 24 hours, a localized pipeline fetches, processes, and logs the top tech industry headlines. This project demonstrates my ability to manage "always-on" infrastructure and automate the ETL (Extract, Transform, Load) lifecycle.

---

## ðŸ› ï¸ System Architecture

Unlike standard scripts, this project is hosted on my private home-lab infrastructure, ensuring 24/7 availability without relying on third-party cloud compute.

* **Hardware:** UGreen DXP4800 Plus (Intel Pentium Gold 8505 NAS)
* **Orchestration:** Docker + Portainer
* **Runtime:** Python 3.9-slim (Debian-based)
* **Scheduling:** Linux `cron` utility
* **Version Control:** Automated headless Git commits via Personal Access Token (PAT)

---

## ðŸ“‹ How It Works

The pipeline follows a strict four-step process every morning:

1.  **Extraction:** At 09:00 AM, the `cron` daemon within the Docker container triggers `tracker.py`.
2.  **Transformation:** The script queries the NewsAPI for TechCrunch headlines, filters the top 5 results, and converts the JSON response into Markdown syntax.
3.  **Local Storage:** The script appends the new entries to `DAILY_LOG.md` with a timestamp.
4.  **Sync:** The system executes a Git push to the main branch, updating the remote repository and maintaining a persistent activity record.

---

## ðŸ“‚ Repository Structure

| File | Description |
| :--- | :--- |
| `tracker.py` | Main logic for API interaction and Git automation. |
| `DAILY_LOG.md` | The cumulative archive of all fetched tech headlines. |
| `requirements.txt` | Python dependencies (Requests library). |

---

## ðŸ“ˆ Future Enhancements
- [ ] Add Sentiment Analysis to headlines using `TextBlob`.
- [ ] Implement a Slack/Discord notification when a high-priority keyword is found.
- [ ] Create a Streamlit dashboard to visualize headline frequency trends.

---

> **Note:** This project is a demonstration of DevOps and automation skills. All commits are generated by my NAS server.
